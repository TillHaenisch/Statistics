{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstmal Daten einlesen: Die Datei all.txt enthält den kompletten Text meines Datenbank-Buchs https://leanpub.com/realtionaledatenbanken/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2427"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile = sc.textFile(\"all.txt\")\n",
    "textFile.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir brauchen eine Hilfsfunktion, die die Zeilen in einzelne Wörter zerlegt.\n",
    "Hier könnte man dann auch noch ein bisschen \"sauber machen\", also etwa Formatierungszeichen\n",
    "entfernen, Schreibweisen korrigieren, Umlaute entfernen usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    return line.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt geht's los: Zunächst mal erzeugen wir ein RDD, das alle Wörter des Texts enthält. Die Datei enthölt 2427 Zeilen und 32674 Wörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2427\n",
      "32674\n"
     ]
    }
   ],
   "source": [
    "words=textFile.flatMap(parse_line)\n",
    "print textFile.count()\n",
    "print words.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt machen wir uns ein pair RDD, das jedes Wort und die bisherige Anzahl (1) enthält"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'#', 1), (u'Einleitung', 1), (u'Datenbanken', 1), (u'sind', 1), (u'aus', 1)]\n"
     ]
    }
   ],
   "source": [
    "initial_count = words.map(lambda word: (word, 1))\n",
    "print initial_count.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das war die Map-Phase. Jetzt fassen wir die gleichen Wörter zusammen und zählen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'', 5264), (u'Punkten', 1), (u'Basiert', 1), (u'Sprache', 1), (u'(select)', 1), (u'gleichzeitig,', 1), (u'Schl\\xfcsselattribut', 1), (u'validates_uniqueness_of', 1), (u'Transaktion', 28), (u'gerade', 1)]\n"
     ]
    }
   ],
   "source": [
    "word_count = initial_count.reduceByKey(lambda a, b: a+b)\n",
    "print word_count.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oder alles auf einmal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = (textFile\n",
    "    .flatMap(parse_line)\n",
    "    .map(lambda word: (word, 1))\n",
    "    .reduceByKey(lambda a, b: a+b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen natürlich die häufigsten Wörter sehen ... wir sortieren nach der negativen Anzahl, um die Wörter in absteigender Anzahl zu erhalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'', 5264), (u'die', 768), (u'der', 651), (u'in', 339), (u'und', 335), (u'ist', 280), (u'von', 275), (u'auf', 252), (u'eine', 249), (u'|', 232), (u'werden', 230), (u'wird', 212), (u'ein', 201), (u'zu', 192), (u'den', 190), (u'das', 174), (u'nicht', 171), (u'einer', 168), (u'mit', 155), (u'werden.', 152), (u'f\\xfcr', 137), (u'bei', 136), (u'Daten', 133), (u'werden,', 127), (u'Die', 127), (u'etwa', 127), (u'=', 127), (u'sind', 125), (u'dass', 124), (u'oder', 123), (u'im', 119), (u'sich', 114), (u'es', 113), (u'als', 113), (u'nur', 105), (u'kann', 100), (u'Datenbank', 99), (u'auch', 97), (u'des', 94), (u'einem', 92), (u'einen', 90), (u'diese', 89), (u'Datenbanken', 89), (u'k\\xf6nnen', 85), (u'wie', 84), (u'aber', 84), (u'zur', 83), (u'dann', 79), (u'aus', 78), (u'wenn', 73)]\n"
     ]
    }
   ],
   "source": [
    "print word_count.takeOrdered(50, key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mal schauen, wieviele Woerter nur einmal vorkommen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4709\n"
     ]
    }
   ],
   "source": [
    "singletons = word_count.filter(lambda (word,count): count == 1)\n",
    "print singletons.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
